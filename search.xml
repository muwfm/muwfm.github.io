<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop集群的搭建</title>
    <url>/2020/02/16/Hadooop%E9%9B%86%E7%BE%A4%E7%9A%84%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<h2 id="hadoop集群的搭建"><a href="#hadoop集群的搭建" class="headerlink" title="hadoop集群的搭建"></a>hadoop集群的搭建</h2><p>1:安装VM，在VM中安装三台虚拟机，安装linux系统<br>先安装一台虚拟机，然后克隆其他两台。（三台虚拟机时间相差不能超过一分钟）<br>同步网络时间命令</p>
<pre><code>yum install ntp ntpupdate
ntpdate cn.pool.ntp.org</code></pre><p>手动设置时间 </p>
<pre><code>date -s &quot;2019-07-15 14:42:50&quot;</code></pre><hr>
<p>2:虚拟机配置</p>
<p>安装时选择简单服务器版本（不需要桌面）</p>
<p>2.1:配置网络：</p>
<pre><code>cd /etc/sysconfig/network-scripts
ls
vim ifcfg-eth0</code></pre><p><img src="https://img-blog.csdnimg.cn/20200218182817198.jpg" alt=""><br>将    ONBOOT设置为yes,</p>
<p>然后输入:wq 保存退出</p>
<p><img src="https://img-blog.csdnimg.cn/20200218194657854.png" alt=""><br>重启网络服务，输入以下命令</p>
<pre><code>service network restart</code></pre><p><img src="https://img-blog.csdnimg.cn/20200218195624674.png" alt=""><br>查询虚拟机IP地址<br>ifconfig</p>
<p><img src="https://img-blog.csdnimg.cn/20200218194759425.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<hr>
<p>3：使用Xshell 远程连接新建的linux系统</p>
<p><img src="https://img-blog.csdnimg.cn/20200218194813845.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p><img src="https://img-blog.csdnimg.cn/20200218194829640.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>然后接受秘钥，连接成功</p>
<p><img src="https://img-blog.csdnimg.cn/20200218194841690.png" alt=""></p>
<hr>
<p>4:给GentOS系统安装jdk并配置环境变量(使用Xsheel和XFtp操作)</p>
<p>4.1:创建一个soft目录</p>
<pre><code>cd /usr/local/
ls
mkdir soft
ls</code></pre><p><img src="https://img-blog.csdnimg.cn/20200218194856414.png" alt=""></p>
<p>4.2:使用Xftp上传jdk-8u192-linux-x64.tar.gz和hadoop-2.6.0.tar.gz压缩包到soft目录下<br>先在Xshell中点击下图1方框打开Xftp,然后拖拽需要的文件到linux系统否soft目录下<br>如下图</p>
<p><img src="https://img-blog.csdnimg.cn/2020021819491340.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>4.3对jdk-8u192-linux-x64.tar.gz以及hadoop-2.6.0.tar.gz压缩包进行解压（解压缩即是安装）</p>
<pre><code>tar -zxvf  jdk-8u192-linux-x64.tar.gz
tar -zxvf  hadoop-2.6.0.tar.gz</code></pre><p><img src="https://img-blog.csdnimg.cn/202002181949327.png" alt=""></p>
<p>为节省存储空间解压后删除压缩包</p>
<p><img src="https://img-blog.csdnimg.cn/20200218194952581.png" alt=""></p>
<p>4.4配置jdk的环境变量<br>配置前可以查看一下（GentOS 默认安装了1.7版本低jdk）</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195003799.png" alt=""></p>
<p>开始配置（解压的是1.8版本，配置成功后输入java -version测试一下）</p>
<pre><code>vim /etc/profile
export JAVA_HOME=/usr/local/soft/jdk......     
export PATH=.:$JAVA_HOME/bin:$PATH</code></pre><p><img src="https://img-blog.csdnimg.cn/2020021819501512.png" alt=""></p>
<p>保存退出 :wq</p>
<p>source /etc/ profile  (刷新)<br>echo $JAVA_HOME (此命令配置好环境变量后可以查看jdk版本信息)</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195029307.png" alt=""></p>
<p>使用Java –version测试配置（发现已经变成1.8版本，配置成功）<br><img src="https://img-blog.csdnimg.cn/20200218195043544.png" alt=""></p>
<hr>
<p>5.克隆虚拟机</p>
<p>*在vmware设置-克隆（虚拟机要关机，jdk要配置好）</p>
<p>*选择克隆当前状态的虚拟机</p>
<p><img src="https://img-blog.csdnimg.cn/2020021819505624.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>选择创建完整克隆</p>
<p><img src="https://img-blog.csdnimg.cn/2020021819510776.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>将另外两个虚拟机克隆好。</p>
<p>关机状态下配置mac地址</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195120185.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p><img src="https://img-blog.csdnimg.cn/20200218195135175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>记录下生成的mac地址<br>（后续修改vim /etc/sysconfig /network-scripts/ifcfg-eth0 配置文件时需要）第六大步（配置好另外两台虚拟机，并在XShell上建立连接，具体步骤如下）（亲历：开启node1,node2虚拟机前需要将master虚拟机打开，防止争抢IP）</p>
<hr>
<p>6.1 进入/etc/sysconfig/network/ 打开ifconfig-eth0文件 </p>
<p>6.2修改HWADDR为对应的mac地址（输入自己的，而且对应node1对应<br>node1 node2对应node2）</p>
<p>6.3删除绑定mac地址文件rm -rf /etc/udev/rules.d/70-persistent-net.rules</p>
<p>6.4  reboot重启</p>
<p>6.5获取ip ifconfig</p>
<p>6.6在xshell建立连接 输入对应ip建立连接</p>
<hr>
<p>7设置子节点的IP（以下1,2,3,4,5步骤每个虚拟机都要操作）</p>
<p>7.1使用命令service network restart 重启网卡</p>
<p>7.2关闭防火墙，使用命令service iptables stop</p>
<p>7.3关闭防火墙的自动启动，使用命令chkconfig iptables off</p>
<p>7.4设置主机名，修改配置文件vi /etc/sysconfig/network</p>
<p>*修改主机名 vi /etc/sysconfig/network</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195150829.png" alt=""></p>
<p>7.5设置主机名与ip的映射，修改配置文件vi /etc/hosts</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195209932.png" alt=""></p>
<p>7.6将修改后的hosts文件从主节点拷贝到node1和node2节点<br>命令：</p>
<pre><code>scp /etc/hosts node1:/etc/hosts
scp /etc/hosts node2:/etc/hosts</code></pre><hr>
<p>8.设置ssh免密码登录<br>  8.1主节点执行命令ssh-keygen -t rsa 产生密钥 一直回车</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195221363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>将密钥拷贝到其他两个子节点，命令如下：</p>
<pre><code>ssh-copy-id -i node1 
ssh-copy-id -i node2</code></pre><p>实现免密码登录到子节点。<br>验证命令，在主节点 通过命令： ssh node1<br>第一次需要输入密码，后面可以不需要输入密码登录<br>退出 命令 exit</p>
<p>8.2实现主节点master本地免密码登录（子节点不需要执行，仅在主节点执行）</p>
<p>首先进入到/root<br>cd  /root<br>再进入进入到 ./.ssh目录下<br>cd ./.ssh/</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195236351.png" alt=""></p>
<p>然后将公钥写入本地执行命令</p>
<pre><code>cat ./id_rsa.pub &gt;&gt; ./authorized_keys</code></pre><p><img src="https://img-blog.csdnimg.cn/20200218195251245.png" alt=""></p>
<hr>
<p>9.修改hadoop的几个组件的配置文件 进入/usr/local/soft/hadoop-2.6.0/etc/hadoop 目录下(请一定要注意配置文件内容的格式，可以直接复制过去黏贴。不要随意改)</p>
<p>9.1修改master中hadoop的一个配置文件/usr/local/soft/etc/hadoop/slaves,删除原来的所有内容，修改为如下<br>node1<br>node2</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195302591.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>9.2 修改hadoop-env.sh文件<br>加上一句</p>
<pre><code>export JAVA_HOME=/usr/local/soft/jdk1.8.0_171</code></pre><p><img src="https://img-blog.csdnimg.cn/20200218195316167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>9.3修改 core-site.xml<br>将下面的配置参数加入进去修改成对应自己的</p>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;fs.defaultFS&lt;/name&gt;
&lt;value&gt;hdfs://master:9000&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
&lt;value&gt;/usr/local/soft/hadoop-2.6.0/tmp&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;fs.trash.interval&lt;/name&gt;
&lt;value&gt;1440&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;</code></pre><p><img src="https://img-blog.csdnimg.cn/20200218195331926.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>9.4修改 hdfs-site.xml 将dfs.replication设置为1</p>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;dfs.replication&lt;/name&gt;
&lt;value&gt;1&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;dfs.permissions&lt;/name&gt;
&lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;</code></pre><p><img src="https://img-blog.csdnimg.cn/20200218195345157.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>9.5修改文件yarn-site.xml</p>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
&lt;value&gt;master&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
&lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
&lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;
&lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
&lt;value&gt;604800&lt;/value&gt;
&lt;/property&gt;
&lt;/configuration&gt;</code></pre><p><img src="https://img-blog.csdnimg.cn/202002181954004.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>9.6修改 mapred-site.xml（将mapred-site.xml.template 复制一份为 mapred-site.xml)（cp <src> <target>     复制&amp;粘贴文件 cp -r <src> <target>     复制&amp;粘贴文件或目录）</p>
<pre><code>&lt;configuration&gt;
&lt;property&gt;
&lt;name&gt;mapreduce.framework.name&lt;/name&gt;
&lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;
&lt;property&gt;  
&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;  
&lt;value&gt;master:10020&lt;/value&gt;  
&lt;/property&gt;  
&lt;property&gt;  
&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;  
&lt;value&gt;master:19888&lt;/value&gt;  
&lt;/property&gt; 
&lt;/configuration&gt;</code></pre><p><img src="https://img-blog.csdnimg.cn/20200218195412708.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<hr>
<p>10.将hadoop的安装目录分别拷贝到其他子节点</p>
<pre><code>scp -r /usr/local/soft/hadoop-2.6.0  node1:/usr/local/soft/
scp -r /usr/local/soft/hadoop-2.6.0  node2:/usr/local/soft/</code></pre><hr>
<p>11.启动hadoop</p>
<hr>
<p>12.<br>首先看下主节点hadoop-2.6.0目录下有没有tmp文件夹。<br>如果没有 执行一次格式化命令：</p>
<pre><code>./bin/hdfs namenode -format</code></pre><p>会生成tmp文件。然后<br>/usr/local/soft/hadoop-2.6.0目录下<br>启动执行</p>
<pre><code>./sbin/start-all.sh</code></pre><p>启动完成后验证进程<br>主节点进程：namenode/ secondarnamenode/resourcemanager</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195426906.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>子节点进程 datanode /nodenodemanager</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195438576.png" alt=""></p>
<p>验证hdfs：<br>可以登录浏览器地址：192.168.3.128:50070 (自己的IP地址加上50070端口 还有一个8088端口也可以查看)</p>
<p>看到下面页面证明 hdfs装好了<br>下图是已经创建了一个hdfs上的目录，刚装好的hadoop应该是空的什么都没有</p>
<p><img src="https://img-blog.csdnimg.cn/20200218195451614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>如果第一次启动失败了，请重新检查配置文件或者哪里步骤少了。<br>再次重启的时候<br>需要手动将每个节点的tmp目录删除<br>/usr/local/soft/hadoop-2.6.0/tmp</p>
<p>然后执行将namenode格式化<br>在主节点执行命令</p>
<pre><code>./bin/hdfs namenode -format</code></pre><p><img src="https://img-blog.csdnimg.cn/2020021819550584.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDUxMjY2MA==,size_16,color_FFFFFF,t_70" alt=""></p>
<p>2020/2/18 20:54:23 </p>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据总结Linux篇章</title>
    <url>/2021/05/31/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%80%BB%E7%BB%93Linux/</url>
    <content><![CDATA[<hr>
<ul>
<li><h2 id="Linux常用高级指令"><a href="#Linux常用高级指令" class="headerlink" title="Linux常用高级指令"></a>Linux常用高级指令</h2></li>
</ul>
<table>
<thead>
<tr>
<th align="left">指令代码</th>
<th align="left">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="left">df -h</td>
<td align="left">查看磁盘存储情况</td>
</tr>
<tr>
<td align="left">top</td>
<td align="left">查看内存</td>
</tr>
<tr>
<td align="left">netstat -tunlp | grep 端口号</td>
<td align="left">查看端口占用情况</td>
</tr>
<tr>
<td align="left">uptime</td>
<td align="left">系统运行时长和平均负载</td>
</tr>
<tr>
<td align="left">ps -aux</td>
<td align="left">查看进程</td>
</tr>
</tbody></table>
<h5 id="Shell中提交了一个脚本，进程号已经不知道了，但是需要kill掉这个进程，怎么操作"><a href="#Shell中提交了一个脚本，进程号已经不知道了，但是需要kill掉这个进程，怎么操作" class="headerlink" title="Shell中提交了一个脚本，进程号已经不知道了，但是需要kill掉这个进程，怎么操作?"></a>Shell中提交了一个脚本，进程号已经不知道了，但是需要kill掉这个进程，怎么操作?</h5><p><code>ssh $i &quot;ps -ef | grep XXX | grep -v grep |awk &#39;{print $2}&#39; | xargs kill&quot;</code></p>
<ol>
<li>ps -ef ：是linux里查看所有进程的命令。</li>
<li>grep -v grep ：是列出的进程中去除含有关键字grep的进程</li>
<li>awk ‘{print $2}’：是打印过滤后的行的第二列，正好是进程hao</li>
<li>Xargs kill -9：xargs命令是用来把前面命令的输出结果（pid）作为kill -9命令的参数，并执行该命令。</li>
</ol>
<p>👉：cut -c 9-15 &lt;=&gt; awk ‘{print $2}’</p>
<hr>
<ul>
<li><h2 id="shell中单引号双引号"><a href="#shell中单引号双引号" class="headerlink" title="shell中单引号双引号"></a>shell中单引号双引号</h2><table>
<thead>
<tr>
<th>指令代码</th>
<th>指令输出</th>
</tr>
</thead>
<tbody><tr>
<td>echo ‘$do_date’</td>
<td>$do_date</td>
</tr>
<tr>
<td>echo “$do_date”</td>
<td>2019-02-10</td>
</tr>
<tr>
<td>echo “‘$do_date’”</td>
<td>‘2019-02-10’</td>
</tr>
<tr>
<td>echo ‘“$do_date”‘</td>
<td>“$do_date”</td>
</tr>
<tr>
<td>echo <code>date</code></td>
<td>2019年 05月 02日 星期四 21:02:08 CST</td>
</tr>
</tbody></table>
<hr>
<ul>
<li><h2 id=""><a href="#" class="headerlink" title=""></a></h2></li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux</title>
    <url>/2020/08/19/linux/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Sql学习记录</title>
    <url>/2021/06/07/Spark_Sql%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>Markdown语法</title>
    <url>/2021/05/28/markdown%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<figure class="highlight java"><table><tr><td class="code"><pre><code class="hljs java">yum install ntp ntpupdate<br></code></pre></td></tr></table></figure>

<h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><hr>
<h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><hr>
<h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><hr>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th></th>
</tr>
</thead>
<tbody><tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<hr>
<p>$$</p>
<p>$$</p>
]]></content>
  </entry>
  <entry>
    <title>谷歌浏览器Chhrome必装的几款神级实用插件</title>
    <url>/2020/02/16/%E8%B0%B7%E6%AD%8C%E6%B5%8F%E8%A7%88%E5%99%A8chhrome%E5%BF%85%E8%A3%85%E7%9A%84%E5%87%A0%E6%AC%BE%E7%A5%9E%E7%BA%A7%E5%AE%9E%E7%94%A8%E6%8F%92%E4%BB%B6/</url>
    <content><![CDATA[<p>首先给大家推荐三款使用最多的浏览器：谷歌、360极速、Edge。其中首推谷歌浏览器，当然谷歌浏览器强大之处在于它的强大的插件，没有插件你的浏览器就相当于一台没有装系统的裸机。接下来推荐几款chrome必备的神级实用插件。</p>
<h3 id="1-下载与安装谷歌浏览器"><a href="#1-下载与安装谷歌浏览器" class="headerlink" title="1.下载与安装谷歌浏览器"></a>1.下载与安装谷歌浏览器</h3><p>直接百度搜索chrome，第一个就是他的官网，进入官网进行下载。但是很多人进不去官网。这只是单纯的网络问题，不需要科学上网，你可以更换更流畅的网络。或者直接在我的公众号回复<strong>谷歌</strong>，获取Chrome下载链接。注意它的安装路径只默认的也就是C盘不可以更改。</p>
<h3 id="2-安装插件"><a href="#2-安装插件" class="headerlink" title="2.安装插件"></a>2.安装插件</h3><p>如果你没有翻墙软件，你就不可以进入谷歌商店，你只能在其他地方获取下载插件然后再安装到你的谷歌浏览器，在这里推荐一款插件“谷歌商店助手”，安装这个插件之后你就可以不用翻墙就能进入chrome商店，也不需要在别处获取插件，但仅限于进入商店，像YouTube这样的网页是做不到的。在我的公众号回复<strong>谷歌助手</strong>进行下载，下载好后再解压压缩包。将解压好后的整个文件夹拖拽到谷歌扩展插件界面即可。</p>
<h3 id="3-infinity新标签页（pro）-插件1"><a href="#3-infinity新标签页（pro）-插件1" class="headerlink" title="3.infinity新标签页（pro）-插件1"></a>3.infinity新标签页（pro）-插件1</h3><p>由于谷歌浏览器是老外使用的，所以在浏览器打开新标页总是会覆盖原网页，而不是在新的标签页打开。而且没有很好的方法解决。所以安装infinity新标签页（pro）就可以完美的解决这一问题。而且infinity新标签页（pro）的快速导航和美观界面让其成为chrome应用商店最后欢迎的插件之一。</p>
<h3 id="4-Tampermonkey-插件2"><a href="#4-Tampermonkey-插件2" class="headerlink" title="4.Tampermonkey-插件2"></a>4.Tampermonkey-插件2</h3><p>tampermonkey插件是一个免费的浏览器扩展和最为流行的用户脚本管理器，拥有适用于 Chrome, Microsoft Edge, Safari, Opera Next、Firefox等多个浏览器的不同版本，能够方便管理不同的脚本。虽然有些受支持的浏览器拥有原生的用户脚本支持，但 tampermonkey脚本将在您的用户脚本管理方面提供更多的便利，它可以提供了诸如便捷脚本安装、自动更新检查、标签中的脚本运行状况速览、内置的编辑器等众多功能，同时tampermonkey还有可能正常运行原本并不兼容的脚本，是浏览器最好的辅助插件，需要的朋友可以下载。</p>
<h3 id="5-AdGuard广告拦截器-插件3"><a href="#5-AdGuard广告拦截器-插件3" class="headerlink" title="5.AdGuard广告拦截器-插件3"></a>5.AdGuard广告拦截器-插件3</h3><p>一款无与伦比的广告拦截扩展，用以对抗各式广告与弹窗。可以拦截 Facebook、YouTube 和其它所有网站的广告。你在爱奇艺、腾讯、优酷看视频的所有广告都可去出掉。功能很强大，谁用谁知道。</p>
<h3 id="6-bilibili哔哩哔哩下载助手-插件4"><a href="#6-bilibili哔哩哔哩下载助手-插件4" class="headerlink" title="6.bilibili哔哩哔哩下载助手-插件4"></a>6.bilibili哔哩哔哩下载助手-插件4</h3><p>bilibili 哔哩哔哩 B站 下载助手 帮你下载版权受限（能看不能缓存）的 番剧 视频。再也不用找第三方软件去下载B站的视频了。</p>
<h3 id="7-IDM-Integration-Module-插件5"><a href="#7-IDM-Integration-Module-插件5" class="headerlink" title="7.IDM Integration Module-插件5"></a>7.IDM Integration Module-插件5</h3><p>谷歌浏览器非常好用，但是下载任务管理一直不行。即使升级了无数次版本，Chrome的自带下载器功能依然十分鸡肋，还会限制文件下载速度和数量，底部的状态栏也很不友好。推荐的就是IDM integration module，也就是传说中的IDM下载管理器。下载知乎、微博视频或者网页视频都不在话下。根据IDM官网的回应：现在Chrome官方商店中可以找到的所有IDM扩展程序都是假的，不应使用。我们的扩展程序隐藏在谷歌商店中，也无法进行搜索。所以在我的公众号号回复<strong>IDM</strong>。下载的是一个.exe可执行文件。安装即可。之后默认会安装到你的谷歌浏览器。</p>
]]></content>
      <categories>
        <category>谷歌</category>
      </categories>
      <tags>
        <tag>chrome</tag>
        <tag>makedown</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据总结Hadoop篇</title>
    <url>/2021/06/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%80%BB%E7%BB%93hadoop%E7%AF%87/</url>
    <content><![CDATA[<hr>
<ul>
<li><h2 id="简单的集群搭建过程："><a href="#简单的集群搭建过程：" class="headerlink" title="简单的集群搭建过程："></a>简单的集群搭建过程：</h2><ol>
<li><p>JDK安装</p>
</li>
<li><p>配置SSH免密登陆</p>
</li>
<li><p>配置hadoop核心文件</p>
</li>
<li><p>格式化namenode</p>
</li>
</ol>
</li>
<li><h2 id="HDFS读写流程"><a href="#HDFS读写流程" class="headerlink" title="HDFS读写流程"></a>HDFS读写流程</h2></li>
<li><h5 id="节点介绍"><a href="#节点介绍" class="headerlink" title="节点介绍"></a>节点介绍</h5></li>
</ul>
<ol>
<li><p>NameNode管理文件系统的命名空间，记录每个文件中各个块所在的数据节点信息。维护文件系统树内所有的文件和目录，以命名空间镜像文件fsimage和编辑日志文件edits保存在本地磁盘。</p>
</li>
<li><p>datanode是文件系统的工作节点，根据需要存储和检索数据块，并定期向namenode发送它们所存储的块的列表。</p>
</li>
<li><p>SecondaryNameNode定期通过编辑日志edits合并命名空间镜像文件fsimage。</p>
<p><img src="https://wyzm.oss-cn-beijing.aliyuncs.com/1622706277088.png" alt=""></p>
</li>
</ol>
<ul>
<li><h5 id="读流程"><a href="#读流程" class="headerlink" title="读流程"></a>读流程</h5><p> 1、 打开分布式文件：调用DFS.open()方法<br> 2、 从NameNode获得DataNode地址：DFS使用RPC调用NameNode，NameNode返回含有该副本的DataNode地址。返回一个输入流FSDataInputStream对象。<br> 3、链接到DataNode：使用输入流read()方法，从而链接到DataNode。<br> 4、读取DataNode：反复调用read()方法，从而将数据从DataNode传输到客户端。<br> 5、读取其它的DataNode直到完成：到达块的末端的时候，输入流关闭与DataNode的连接，寻找下一个DataNode并继续读取数据。<br> 6、完成读取，关闭连接：即调用数据流FSDataInputStream.close()方法</p>
</li>
<li><h5 id="写流程"><a href="#写流程" class="headerlink" title="写流程"></a>写流程</h5><p> 1、客户端向NameNode发送请求，请求上传文件。：调用DFS.create()方法。<br> 2、NameNode处理请求，检查客户端是否有权限上传，路径是否合法等。<br> 3、客户端根据自己设置块的大小，开始上传第一个块，默认0～128M，NameNode根据客户端上传文件的副本数（默认为3），返回指定数量的DataNode节点。<br> 4、客户端根据返回的DataNode节点建立传输通道，节点响应由近及远建立通道。<br> 5、客户端每读取64k的数据，封装为一个packet（数据包，传输的基本单位），并将packet发送到通道的下一个节点，每个节点收到packet并响应。<br> 6、一个块传输完成通道关闭并开始第二个块的传输，直至最后一个块传输完成，NameNode向客户端响应传输完成！<br> 7、客户端关闭输入流。</p>
</li>
<li><h2 id="HDFS小文件处理"><a href="#HDFS小文件处理" class="headerlink" title="HDFS小文件处理"></a>HDFS小文件处理</h2><ol>
<li><p>开启jvm重用。</p>
<ol>
<li><p>JVM重用技术不是指同一个Job的两个或两个以上的task可以同时运行在同一个JVM上，而是说这些task按顺序执行。</p>
</li>
<li><p>开启后同一个job的顺序执行的task可以共享一个JVM，第二轮的map可以重用前一轮的JVM。</p>
</li>
<li><p>为一个task启动一个新的JVM将耗时一秒，对于时间很短的task，会频繁启停JVM产生开销。</p>
<p>注：会一直占用使用到的task插槽，以便重用，直到任务结束才能释放，如果某个”不平衡的”job中有几个reduce task执行的时间要比其它reduce task消耗的时间多的多的话，那么保留的插槽就会一直空闲着却无法被其它的job使用，直到所有的task都结束才会释放。</p>
<p>👉mapred.job.reuse.jvm.num.tasks=10 或者 set mapred.job.reuse.jvm.num.tasks=10</p>
</li>
</ol>
</li>
<li><p>har归档（Hadoop Archive）</p>
<ol>
<li>hadoop archive -archiveName 20131101.har /user/hadoop/login/201301/01 /user/hadoop/login/201301/01</li>
</ol>
</li>
<li><p>hadoop fs -rmr /user/hadoop/login/201301/01/<em>.</em>.*</p>
<ol start="3">
<li>hadoop fs -cp /user/hadoop/login/201301/01/20130101.har/*  /user/hadoop/login/201301/01/   </li>
</ol>
</li>
<li><p>CombineTextInputFormat</p>
</li>
</ol>
</li>
</ul>
<hr>
<p>​      </p>
<ul>
<li><h2 id="MapReduce过程"><a href="#MapReduce过程" class="headerlink" title="MapReduce过程"></a>MapReduce过程</h2><h4 id="输入分片—-gt-map阶段—-gt-combiner阶段-可选-—-gt-shuffle阶段—-gt-reduce阶段"><a href="#输入分片—-gt-map阶段—-gt-combiner阶段-可选-—-gt-shuffle阶段—-gt-reduce阶段" class="headerlink" title="输入分片—&gt;map阶段—&gt;combiner阶段(可选)—&gt;shuffle阶段—&gt;reduce阶段"></a>输入分片—&gt;map阶段—&gt;combiner阶段(可选)—&gt;shuffle阶段—&gt;reduce阶段</h4><p> <img src="https://wyzm.oss-cn-beijing.aliyuncs.com/1622698464176.png" alt=""></p>
</li>
</ul>
<p><img src="https://wyzm.oss-cn-beijing.aliyuncs.com/1622698953373.png" alt=""></p>
<ul>
<li><p>流程说明如下：</p>
<ol>
<li><p>输入文件分片split，每一片都由一个MapTask来处理</p>
</li>
<li><p>Map输出的中间结果会先放到环形内存缓冲区中，缓冲区刷写到磁盘（如果一个map输出内容没有超过限制，最终也会发生这个写磁盘的操作）</p>
</li>
<li><p>从缓冲区写到磁盘的时候，会进行分区并排序（分区指的是某个key应该进入到哪个分区，同一分区中的key会进行排序，如果定义了Combiner的话，也会进行combine操作）</p>
</li>
<li><p>在开始reduce之前，先要从分区中抓取数据，相同分区的数据会进入同一个reduce，这一步会从所有的map输出中抓取同一分区的数据，在抓取的过程中伴随着排序及合并的操作。</p>
</li>
<li><p>最后，reduce输出。</p>
</li>
</ol>
</li>
</ul>
<hr>
<ul>
<li><h2 id="shuffle优化"><a href="#shuffle优化" class="headerlink" title="shuffle优化"></a>shuffle优化</h2></li>
<li><p>Map阶段</p>
<ol>
<li>增大环形缓冲区大小，由100M扩大到200M</li>
<li>增大环形缓冲区溢写的比例，由80%扩大到90%</li>
<li>减少对溢写文件的merge次数</li>
<li>不影响业务的前提下，采用Combiner提前合并，减少I/O</li>
</ol>
</li>
<li><p>Reduce阶段</p>
<ol>
<li>合理设置Map和Reduce数量，太少会导致Task等待，太多会导致Map，Reduce任务间竞争资源，造成处理超时等错误。</li>
<li>设置Map、Reduce共存，在map运行到一定程度时，reduce也开始运行，减少reduce的等待时间。</li>
<li>规避使用reduce，因为reduce在用于连接数据集的时候会产生大量的网络消耗。</li>
<li>增大reduce端存储数据的内存的大小。</li>
</ol>
</li>
<li><p>IO传输阶段</p>
<ol>
<li>采用数据压缩的方式，减少网络IO的时间</li>
</ol>
</li>
<li><p>整体<br>（1）NodeManager默认内存8G，需要根据服务器实际配置灵活调整，例如128G内存，配置为100G内存左右，yarn.nodemanager.resource.memory-mb。<br>（2）单任务默认内存8G，需要根据该任务的数据量灵活调整，例如128m数据，配置1G内存，yarn.scheduler.maximum-allocation-mb。<br>（3）mapreduce.map.memory.mb ：控制分配给MapTask内存上限，如果超过会kill掉进程（报：Container is running beyond physical memory limits. Current usage:565MB of512MB physical memory used；Killing Container）。默认内存大小为1G，如果数据量是128m，正常不需要调整内存；如果数据量大于128m，可以增加MapTask内存，最大可以增加到4-5g。<br>（4）mapreduce.reduce.memory.mb：控制分配给ReduceTask内存上限。默认内存大小为1G，如果数据量是128m，正常不需要调整内存；如果数据量大于128m，可以增加ReduceTask内存大小为4-5g。<br>（5）mapreduce.map.java.opts：控制MapTask堆内存大小。（如果内存不够，报：java.lang.OutOfMemoryError）<br>（6）mapreduce.reduce.java.opts：控制ReduceTask堆内存大小。（如果内存不够，报：java.lang.OutOfMemoryError）<br>（7）可以增加MapTask的CPU核数，增加ReduceTask的CPU核数<br>（8）增加每个Container的CPU核数和内存大小<br>（9）在hdfs-site.xml文件中配置多目录<br>（10）NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作。dfs.namenode.handler.count=20 * log2(Cluster Size)，比如集群规模为10台时，此参数设置为60。</p>
</li>
</ul>
<hr>
<ul>
<li><h2 id="Yarn工作机制"><a href="#Yarn工作机制" class="headerlink" title="Yarn工作机制"></a>Yarn工作机制</h2><h4 id="一个资源调度平台，负责为运算程序提供服务器资源。其上可运行各类分布式运算程序。"><a href="#一个资源调度平台，负责为运算程序提供服务器资源。其上可运行各类分布式运算程序。" class="headerlink" title="一个资源调度平台，负责为运算程序提供服务器资源。其上可运行各类分布式运算程序。"></a>一个资源调度平台，负责为运算程序提供服务器资源。其上可运行各类分布式运算程序。</h4><p><img src="https://wyzm.oss-cn-beijing.aliyuncs.com/1622704195849.png" alt=""></p>
</li>
<li><h4 id="Yarn调度器：FIFO、容量调度器、公平调度器"><a href="#Yarn调度器：FIFO、容量调度器、公平调度器" class="headerlink" title="Yarn调度器：FIFO、容量调度器、公平调度器"></a>Yarn调度器：FIFO、容量调度器、公平调度器</h4><ol>
<li><p>FIFO：支持单队列、先进先出、生产环境不会用</p>
</li>
<li><p>容量调度器：支持多队列、保证先进入的任务先执行     针对中小公司   Apache</p>
</li>
<li><p>公平调度器：支持多队列、保证每个任务公平享有队列资源     针对大厂     CDH</p>
</li>
</ol>
</li>
<li><h4 id="Hadoop宕机"><a href="#Hadoop宕机" class="headerlink" title="Hadoop宕机"></a>Hadoop宕机</h4><h5 id="如果MR造成系统宕机，此时要控制Yarn同时运行的任务数，和每个任务申请的最大内存。"><a href="#如果MR造成系统宕机，此时要控制Yarn同时运行的任务数，和每个任务申请的最大内存。" class="headerlink" title="如果MR造成系统宕机，此时要控制Yarn同时运行的任务数，和每个任务申请的最大内存。"></a>如果MR造成系统宕机，此时要控制Yarn同时运行的任务数，和每个任务申请的最大内存。</h5><h5 id="如果写入文件过快造成NameNode宕机，那么调高Kafka的存储大小，控制从Kafka到Hdfs的写入速度。"><a href="#如果写入文件过快造成NameNode宕机，那么调高Kafka的存储大小，控制从Kafka到Hdfs的写入速度。" class="headerlink" title="如果写入文件过快造成NameNode宕机，那么调高Kafka的存储大小，控制从Kafka到Hdfs的写入速度。"></a>如果写入文件过快造成NameNode宕机，那么调高Kafka的存储大小，控制从Kafka到Hdfs的写入速度。</h5></li>
<li><h2 id="Hadoop解决数据倾斜方法"><a href="#Hadoop解决数据倾斜方法" class="headerlink" title="Hadoop解决数据倾斜方法"></a>Hadoop解决数据倾斜方法</h2></li>
</ul>
]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
      </tags>
  </entry>
</search>
